{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Coherence: Comparing levels of explanation\n",
    "\n",
    "In this notebook we provide a basic implementation for running simulations of the computational-level theories of <span style=\"font-variant: small-caps;\">Coherence</span> and <span style=\"font-variant: small-caps;\">Discriminating Coherence</span>. In addition, there is support for simulating the connectionist algorithmic-level theory for <span style=\"font-variant: small-caps;\">Discriminating Coherence</span>, referred to as ```connectionistDiscriminatingCoherence```.\n",
    "\n",
    "This notebook makes extensive use of ```mathlib``` for Scala. It is recommended to read [Chapter 9: Scala and mathlib](https://computationalcognitivescience.github.io/lovelace/part_iii/mathlib) for an introduction on this library or to explore the [tutorials](../tutorial/00.00-scala_preface.ipynb).\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>Notice.</b> If you are a student in BKI334 Theoretical Modelling for Cognitive Science, please not that this code was developed not specifically for the course. It may need to be modified to suit your own research questions and it may not be bug free.</div>\n",
    "\n",
    "For completeness here are the computational-level formalizations of <span style=\"font-variant: small-caps;\">Coherence</span> and <span style=\"font-variant: small-caps;\">Discriminating Coherence</span>. We use the truth value assignment variants.\n",
    "\n",
    "<span style=\"font-variant: small-caps;\">Coherence</span>\n",
    "\n",
    "*Input:* A graph $G=(V,E)$ with vertex set $V$ and edge set $E\\subseteq V\\times V$ that partitions into positive constraints $C^+$ and negative constraints $C^-$ (i.e., $C^+\\cup C^-=E$ and $C^+\\cap C^-=\\varnothing$) and a weight function $w: E \\rightarrow \\mathbb{R}$.\n",
    "\n",
    "*Output:* A truth value assignemnt $T:V \\rightarrow \\{true, false\\}$ such that $Coh(T)=Coh^+(A,R)+Coh^-(T)$ is maximum. Here, \n",
    "$$\n",
    "Coh^+(T)=\\displaystyle\\sum_{(u,v)\\in C^+}\n",
    "\\begin{cases}\n",
    "w((u,v))\\text{ if }T(u) = T(v)\\\\\n",
    "0\\text{ otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "Coh^-(T)=\\displaystyle\\sum_{(u,v)\\in C^+}\n",
    "\\begin{cases}\n",
    "w((u,v))\\text{ if }T(u) \\ne T(v)\\\\\n",
    "0\\text{ otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "<span style=\"font-variant: small-caps;\">Discriminating Coherence</span>\n",
    "\n",
    "*Input:* A graph $G=(V,E)$ with vertex set $V$ and edge set $E\\subseteq V\\times V$ that partitions into positive constraints $C^+$ and negative constraints $C^-$ (i.e., $C^+\\cup C^-=E$ and $C^+\\cap C^-=\\varnothing$), a weight function $w: E \\rightarrow \\mathbb{R}$ and a data weight function $d:D \\rightarrow\\mathbb{R}$ for favored beliefs $D\\subseteq V$.\n",
    "\n",
    "*Output:* A truth value assignemnt $T:V \\rightarrow \\{true, false\\}$ such that $Coh(T)=Coh^+(T)+Coh^-(T)+Coh^d(T)$ is maximum. Here, \n",
    "$$\n",
    "Coh^+(T)=\\displaystyle\\sum_{(u,v)\\in C^+}\n",
    "\\begin{cases}\n",
    "w((u,v))\\text{ if }T(u) = T(v)\\\\\n",
    "0\\text{ otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "Coh^-(T)=\\displaystyle\\sum_{(u,v)\\in C^+}\n",
    "\\begin{cases}\n",
    "w((u,v))\\text{ if }T(u) \\ne T(v)\\\\\n",
    "0\\text{ otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "Coh^d(T)=\\displaystyle\\sum_{v\\in D}d(v)\n",
    "$$\n",
    "\n",
    "## Importing libraries\n",
    "\n",
    "The following two code chunks import the necessary libraries for running this notebook. On initial runs you may get messages for downloading ```mathlib```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mmathlib.set.SetTheory._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.collection.parallel.CollectionConverters._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.io.File\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.github.tototoshi.csv._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.util._\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`com.markblokpoel::mathlib:0.9.1`\n",
    "import mathlib.set.SetTheory._\n",
    "\n",
    "import $ivy.`org.scala-lang.modules::scala-parallel-collections:1.0.4`\n",
    "import scala.collection.parallel.CollectionConverters._\n",
    "\n",
    "import $ivy.`com.github.tototoshi::scala-csv:1.3.8`\n",
    "import java.io.File\n",
    "import com.github.tototoshi.csv._\n",
    "import scala.util._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Basic Coherence implementation\n",
    "\n",
    "Below is the implementation of <span style=\"font-variant: small-caps;\">Coherence</span>. \n",
    "\n",
    "The function ```def coh(assignment: Map[Vertex, Boolean): Double``` implements $Coh(T)=Coh^+(A,R)+Coh^-(T)$.\n",
    "\n",
    "The function ```def cohPlus(assignment: Map[Vertex, Boolean]): Double``` implements\n",
    "$$\n",
    "Coh^+(T)=\\displaystyle\\sum_{(u,v)\\in C^+}\n",
    "\\begin{cases}\n",
    "w((u,v))\\text{ if }T(u) = T(v)\\\\\n",
    "0\\text{ otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "And the function ```def cohMinus(assignment: Map[Vertex, Boolean]): Double``` implements\n",
    "$$\n",
    "Coh^-(T)=\\displaystyle\\sum_{(u,v)\\in C^+}\n",
    "\\begin{cases}\n",
    "w((u,v))\\text{ if }T(u) \\ne T(v)\\\\\n",
    "0\\text{ otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The output is implemented as an exhaustive search. The following statement returns all possible truth value assignments, i.e., all possible mappings from the set of vertices to the set $\\{true, false\\}$:\n",
    "```\n",
    "vertices.allMappings(Set(true, false))\n",
    "```\n",
    "Then from that set find the mapping(s) that have maximal coherence:\n",
    "```\n",
    ".argMax(coh _)\n",
    "```\n",
    "And if there are more than one optimal solutions, return one at random:\n",
    "```\n",
    ".random.get\n",
    "```\n",
    "\n",
    "We also add a minimal set of basic datastructures. A vertex is represented by a simple ```String``` and an edge in the network (which could be a positive or negative constraint) is represented by a pair of vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtype\u001b[39m \u001b[36mVertex\u001b[39m\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mEdge\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mcoherence\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type Vertex = String\n",
    "type Edge = (Vertex, Vertex)\n",
    "\n",
    "def coherence(\n",
    "    vertices: Set[Vertex],\n",
    "    edges: Set[Edge],\n",
    "    positiveConstraints: Set[Edge],\n",
    "    negativeConstraints: Set[Edge]\n",
    "): Map[Vertex, Boolean] = {\n",
    "    \n",
    "    require(positiveConstraints \\/ negativeConstraints == edges, \"C+ union C- != E\")\n",
    "    require(positiveConstraints /\\ negativeConstraints == Set.empty, \"C+ intersect C- is not empty\")\n",
    "    \n",
    "    \n",
    "    def cohPlus(assignment: Map[Vertex, Boolean]): Int =\n",
    "     positiveConstraints.count((pc: Edge) => {\n",
    "        assignment(pc._1) == true && assignment(pc._2) == true ||\n",
    "        assignment(pc._1) == false && assignment(pc._2) == false\n",
    "     })\n",
    "    \n",
    "    def cohMinus(assignment: Map[Vertex, Boolean]): Int =\n",
    "     negativeConstraints.count((pc: Edge) => {\n",
    "        assignment(pc._1) == true && assignment(pc._2) == false ||\n",
    "        assignment(pc._1) == false && assignment(pc._2) == true\n",
    "     })\n",
    "    \n",
    "    def coh(assignment: Map[Vertex, Boolean]): Int =\n",
    "        cohPlus(assignment) + cohMinus(assignment)\n",
    "    \n",
    "    vertices.allMappings(Set(true, false))\n",
    "    .argMax(coh _)\n",
    "    .random.get\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "A simple example belief network to compute an optimal truth value assignment for. Notice that running this code multiple times will lead to different truth value assignments because multiple assignments have maximum coherence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36melements\u001b[39m: \u001b[32mSet\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mSet\u001b[39m(\u001b[32m\"a\"\u001b[39m, \u001b[32m\"b\"\u001b[39m, \u001b[32m\"c\"\u001b[39m, \u001b[32m\"d\"\u001b[39m)\n",
       "\u001b[36mpc\u001b[39m: \u001b[32mSet\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m)] = \u001b[33mSet\u001b[39m((\u001b[32m\"a\"\u001b[39m, \u001b[32m\"b\"\u001b[39m), (\u001b[32m\"a\"\u001b[39m, \u001b[32m\"c\"\u001b[39m), (\u001b[32m\"b\"\u001b[39m, \u001b[32m\"d\"\u001b[39m))\n",
       "\u001b[36mnc\u001b[39m: \u001b[32mSet\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m)] = \u001b[33mSet\u001b[39m((\u001b[32m\"b\"\u001b[39m, \u001b[32m\"c\"\u001b[39m), (\u001b[32m\"a\"\u001b[39m, \u001b[32m\"d\"\u001b[39m))\n",
       "\u001b[36mres3_3\u001b[39m: \u001b[32mMap\u001b[39m[\u001b[32mVertex\u001b[39m, \u001b[32mBoolean\u001b[39m] = \u001b[33mMap\u001b[39m(\n",
       "  \u001b[32m\"a\"\u001b[39m -> \u001b[32mfalse\u001b[39m,\n",
       "  \u001b[32m\"b\"\u001b[39m -> \u001b[32mtrue\u001b[39m,\n",
       "  \u001b[32m\"c\"\u001b[39m -> \u001b[32mfalse\u001b[39m,\n",
       "  \u001b[32m\"d\"\u001b[39m -> \u001b[32mtrue\u001b[39m\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val elements = Set(\"a\",\"b\",\"c\",\"d\")\n",
    "val pc = Set(\n",
    "    (\"a\",\"b\"),\n",
    "    (\"a\",\"c\"),\n",
    "    (\"b\",\"d\")\n",
    ")\n",
    "val nc = Set(\n",
    "    (\"b\",\"c\"),\n",
    "    (\"a\",\"d\")\n",
    ")\n",
    "coherence(elements, pc \\/ nc, pc, nc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the belief network from [Chapter 5 - Coherece](https://computationalcognitivescience.github.io/lovelace/part_ii/coherence). For convenience, we've added a translation dictionary from belief labels to the descriptions in the network. That way, the output can be printed with nice statements. \n",
    "\n",
    "![Coherence example](https://computationalcognitivescience.github.io/lovelace/assets/img/coherence_capital_example.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\tAmsterdam is the largest city is false\n",
      "b\tNijmegen is the oldest city is true\n",
      "c\tThe Hague is the capital is true\n",
      "d\tAmsterdam is the capital is false\n",
      "e\tNijmegen is the capital is false\n",
      "f\tParliament is in the Hague is true\n",
      "g\tParliament is in Amsterdam is false\n",
      "h\tParliament is in Nijmegen is false\n",
      "i\tPrime minister lives in The Hague is true\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdict\u001b[39m: \u001b[32mMap\u001b[39m[\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m] = \u001b[33mHashMap\u001b[39m(\n",
       "  \u001b[32m\"e\"\u001b[39m -> \u001b[32m\"Nijmegen is the capital\"\u001b[39m,\n",
       "  \u001b[32m\"f\"\u001b[39m -> \u001b[32m\"Parliament is in the Hague\"\u001b[39m,\n",
       "  \u001b[32m\"a\"\u001b[39m -> \u001b[32m\"Amsterdam is the largest city\"\u001b[39m,\n",
       "  \u001b[32m\"i\"\u001b[39m -> \u001b[32m\"Prime minister lives in The Hague\"\u001b[39m,\n",
       "  \u001b[32m\"b\"\u001b[39m -> \u001b[32m\"Nijmegen is the oldest city\"\u001b[39m,\n",
       "  \u001b[32m\"g\"\u001b[39m -> \u001b[32m\"Parliament is in Amsterdam\"\u001b[39m,\n",
       "  \u001b[32m\"d\"\u001b[39m -> \u001b[32m\"Amsterdam is the capital\"\u001b[39m,\n",
       "  \u001b[32m\"c\"\u001b[39m -> \u001b[32m\"The Hague is the capital\"\u001b[39m,\n",
       "  \u001b[32m\"h\"\u001b[39m -> \u001b[32m\"Parliament is in Nijmegen\"\u001b[39m\n",
       ")\n",
       "\u001b[36mbeliefs\u001b[39m: \u001b[32mSet\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mHashSet\u001b[39m(\u001b[32m\"e\"\u001b[39m, \u001b[32m\"f\"\u001b[39m, \u001b[32m\"a\"\u001b[39m, \u001b[32m\"i\"\u001b[39m, \u001b[32m\"b\"\u001b[39m, \u001b[32m\"g\"\u001b[39m, \u001b[32m\"d\"\u001b[39m, \u001b[32m\"c\"\u001b[39m, \u001b[32m\"h\"\u001b[39m)\n",
       "\u001b[36mpc\u001b[39m: \u001b[32mSet\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m)] = \u001b[33mHashSet\u001b[39m(\n",
       "  (\u001b[32m\"a\"\u001b[39m, \u001b[32m\"d\"\u001b[39m),\n",
       "  (\u001b[32m\"d\"\u001b[39m, \u001b[32m\"g\"\u001b[39m),\n",
       "  (\u001b[32m\"e\"\u001b[39m, \u001b[32m\"h\"\u001b[39m),\n",
       "  (\u001b[32m\"f\"\u001b[39m, \u001b[32m\"i\"\u001b[39m),\n",
       "  (\u001b[32m\"c\"\u001b[39m, \u001b[32m\"f\"\u001b[39m),\n",
       "  (\u001b[32m\"b\"\u001b[39m, \u001b[32m\"e\"\u001b[39m)\n",
       ")\n",
       "\u001b[36mnc\u001b[39m: \u001b[32mSet\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m)] = \u001b[33mHashSet\u001b[39m(\n",
       "  (\u001b[32m\"a\"\u001b[39m, \u001b[32m\"b\"\u001b[39m),\n",
       "  (\u001b[32m\"d\"\u001b[39m, \u001b[32m\"e\"\u001b[39m),\n",
       "  (\u001b[32m\"c\"\u001b[39m, \u001b[32m\"e\"\u001b[39m),\n",
       "  (\u001b[32m\"g\"\u001b[39m, \u001b[32m\"i\"\u001b[39m),\n",
       "  (\u001b[32m\"f\"\u001b[39m, \u001b[32m\"g\"\u001b[39m),\n",
       "  (\u001b[32m\"c\"\u001b[39m, \u001b[32m\"d\"\u001b[39m),\n",
       "  (\u001b[32m\"h\"\u001b[39m, \u001b[32m\"i\"\u001b[39m),\n",
       "  (\u001b[32m\"a\"\u001b[39m, \u001b[32m\"c\"\u001b[39m),\n",
       "  (\u001b[32m\"f\"\u001b[39m, \u001b[32m\"h\"\u001b[39m)\n",
       ")\n",
       "\u001b[36moutput\u001b[39m: \u001b[32mMap\u001b[39m[\u001b[32mVertex\u001b[39m, \u001b[32mBoolean\u001b[39m] = \u001b[33mHashMap\u001b[39m(\n",
       "  \u001b[32m\"e\"\u001b[39m -> \u001b[32mfalse\u001b[39m,\n",
       "  \u001b[32m\"f\"\u001b[39m -> \u001b[32mtrue\u001b[39m,\n",
       "  \u001b[32m\"a\"\u001b[39m -> \u001b[32mfalse\u001b[39m,\n",
       "  \u001b[32m\"i\"\u001b[39m -> \u001b[32mtrue\u001b[39m,\n",
       "  \u001b[32m\"b\"\u001b[39m -> \u001b[32mtrue\u001b[39m,\n",
       "  \u001b[32m\"g\"\u001b[39m -> \u001b[32mfalse\u001b[39m,\n",
       "  \u001b[32m\"d\"\u001b[39m -> \u001b[32mfalse\u001b[39m,\n",
       "  \u001b[32m\"c\"\u001b[39m -> \u001b[32mtrue\u001b[39m,\n",
       "  \u001b[32m\"h\"\u001b[39m -> \u001b[32mfalse\u001b[39m\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dict = Map(\n",
    "    \"a\" -> \"Amsterdam is the largest city\",\n",
    "    \"b\" -> \"Nijmegen is the oldest city\",\n",
    "    \"c\" -> \"The Hague is the capital\",\n",
    "    \"d\" -> \"Amsterdam is the capital\",\n",
    "    \"e\" -> \"Nijmegen is the capital\",\n",
    "    \"f\" -> \"Parliament is in the Hague\",\n",
    "    \"g\" -> \"Parliament is in Amsterdam\",\n",
    "    \"h\" -> \"Parliament is in Nijmegen\",\n",
    "    \"i\" -> \"Prime minister lives in The Hague\"\n",
    ")\n",
    "\n",
    "val beliefs = Set(\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\")\n",
    "\n",
    "val pc = Set(\n",
    "    (\"a\",\"d\"),\n",
    "    (\"b\",\"e\"),\n",
    "    (\"c\",\"f\"),\n",
    "    (\"d\",\"g\"),\n",
    "    (\"e\",\"h\"),\n",
    "    (\"f\",\"i\")\n",
    ")\n",
    "\n",
    "val nc = Set(\n",
    "    (\"a\",\"b\"),\n",
    "    (\"a\",\"c\"),\n",
    "    (\"c\",\"d\"),\n",
    "    (\"c\",\"e\"),\n",
    "    (\"d\",\"e\"),\n",
    "    (\"f\",\"g\"),\n",
    "    (\"f\",\"h\"),\n",
    "    (\"g\",\"i\"),\n",
    "    (\"h\",\"i\")\n",
    ")\n",
    "\n",
    "val output = coherence(beliefs, pc \\/ nc, pc, nc)\n",
    "output.toSeq.sortBy(_._1).foreach(kv => println(s\"${kv._1}\\t${dict(kv._1)} is ${kv._2}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Structures\n",
    "\n",
    "To facilitate writing simulation code, we implement several supporting data structures for representating belief networks. \n",
    "\n",
    "## Base Coherence Network\n",
    "\n",
    "The datastructure ```Network``` builds on basic structures to represent a belief network. In math a belief network $N=(V,E)$ consists of a set of vertices and edges. The set of positive constraints $C^+$ and the set of negative constraints $C^-$ are also represented, and we check if indeed $E=C^+\\cup C^-$ as specified in the formal model. Weights for each edge are represented by a ```Map```. This datastructure stores pairs of keys and values, where keys 'point to' the associated value. Here, each edge is a key in the map pointing to a ```Double``` value representing the weight of the edge. For example, the following code would represent two edges and their weights:\n",
    "```\n",
    "Map(\n",
    "  (\"a\",\"b\") -> 0.4,\n",
    "  (\"a\", \"c\") -> 0.8\n",
    ")\n",
    "```\n",
    "For more examples on the ```Map``` datastructure, see [Section 1.05](..//tutorial/01.05-scala_introduction-collections.ipynb#1.5.4-Maps) of the ```mathlib``` tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mNetwork\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class Network(\n",
    "    vertices: Set[Vertex],\n",
    "    edges: Set[Edge],\n",
    "    positiveConstraints: Set[Edge],\n",
    "    negativeConstraints: Set[Edge],\n",
    "    weights: Map[Edge, Double]\n",
    ") {\n",
    "    \n",
    "    require(positiveConstraints \\/ negativeConstraints == edges, \"C+ union C- != E\")\n",
    "    require(positiveConstraints /\\ negativeConstraints == Set.empty, \"C+ intersect C- is not empty\")\n",
    "    \n",
    "    \n",
    "    def constraints = positiveConstraints \\/ negativeConstraints\n",
    "    \n",
    "    def cohPlus(assignment: Map[Vertex, Boolean]): Double = {\n",
    "        def eval(edge: Edge): Double = {\n",
    "            if(assignment(edge._1) == assignment(edge._2)) weights(edge)\n",
    "            else 0.0\n",
    "        }\n",
    "        \n",
    "        positiveConstraints.toList.map(eval).sum\n",
    "    }\n",
    "    \n",
    "    def cohMinus(assignment: Map[Vertex, Boolean]): Double = {\n",
    "        def eval(edge: Edge): Double = {\n",
    "            if(assignment(edge._1) != assignment(edge._2)) weights(edge)\n",
    "            else 0.0\n",
    "        }\n",
    "        \n",
    "        negativeConstraints.toList.map(eval).sum\n",
    "    }\n",
    "    \n",
    "    def coh(assignment: Map[Vertex, Boolean]): Double = {\n",
    "        cohPlus(assignment) + cohMinus(assignment)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating coherence value\n",
    "\n",
    "The datastructure contains functions that are equivalent to the implementation of <span style=\"font-variant: small-caps;\">Coherence</span> above that return the coherence value of a given truth value assignment.\n",
    "\n",
    "Calling the function ```coh``` will return the coherence of the truth value assignment, given the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mnet\u001b[39m: \u001b[32mNetwork\u001b[39m = \u001b[33mNetwork\u001b[39m(\n",
       "  vertices = \u001b[33mSet\u001b[39m(\u001b[32m\"a\"\u001b[39m, \u001b[32m\"b\"\u001b[39m),\n",
       "  edges = \u001b[33mSet\u001b[39m((\u001b[32m\"a\"\u001b[39m, \u001b[32m\"b\"\u001b[39m)),\n",
       "  positiveConstraints = \u001b[33mSet\u001b[39m((\u001b[32m\"a\"\u001b[39m, \u001b[32m\"b\"\u001b[39m)),\n",
       "  negativeConstraints = \u001b[33mSet\u001b[39m(),\n",
       "  weights = \u001b[33mMap\u001b[39m((\u001b[32m\"a\"\u001b[39m, \u001b[32m\"b\"\u001b[39m) -> \u001b[32m0.4\u001b[39m)\n",
       ")\n",
       "\u001b[36mtruthValueAssignment\u001b[39m: \u001b[32mMap\u001b[39m[\u001b[32mString\u001b[39m, \u001b[32mBoolean\u001b[39m] = \u001b[33mMap\u001b[39m(\u001b[32m\"a\"\u001b[39m -> \u001b[32mtrue\u001b[39m, \u001b[32m\"b\"\u001b[39m -> \u001b[32mtrue\u001b[39m)\n",
       "\u001b[36mres6_2\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.4\u001b[39m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val net = Network(\n",
    "    vertices = Set(\"a\", \"b\"),\n",
    "    edges = Set((\"a\", \"b\")),\n",
    "    positiveConstraints = Set((\"a\", \"b\")),\n",
    "    negativeConstraints = Set.empty,\n",
    "    weights = Map((\"a\",\"b\") -> 0.4)\n",
    ")\n",
    "val truthValueAssignment = Map(\"a\" -> true, \"b\" -> true)\n",
    "net.coh(truthValueAssignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminating Coherence Network\n",
    "\n",
    "For belief networks that favor some beliefs being true over others such as in <span style=\"font-variant: small-caps;\">Discriminating Coherence</span>, we provide an additional datastructure ```DiscriminatingNetwork``` that extends ```Network``` with a weights for the data vertices, also represented by a ```Map```. The set of favored beliefs $D$ is only implicitly represented through the discriminating weights, i.e., if a belief does not have a discriminating weight it is not in $D$.\n",
    "\n",
    "The coherence value for truth value assignments, relative to a distriminating coherence network can be computed by calling the function ```coh``` on a discriminating network. It implements $Coh(T)=Coh^+(T)+Coh^-(T)+Coh^d(T)$. Here, ```cohPus``` and ```cohMinus``` are inherited from the base coherence network implementation. The function ```def cohD(assignment: Map[Vertex, Boolean]): Double``` implements the coherence bonus for accepting data beliefs:\n",
    "$$\n",
    "Coh^d(T)=\\displaystyle\\sum_{v\\in D}d(v)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mDiscriminatingNetwork\u001b[39m\n",
       "defined \u001b[32mobject\u001b[39m \u001b[36mDiscriminatingNetwork\u001b[39m"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DiscriminatingNetwork(\n",
    "    vertices: Set[Vertex],\n",
    "    edges: Set[Edge],\n",
    "    positiveConstraints: Set[Edge],\n",
    "    negativeConstraints: Set[Edge],\n",
    "    weights: Map[Edge, Double],\n",
    "    val dataWeights: Map[Vertex, Double]// Adding val to make value public.\n",
    ") extends Network(\n",
    "    vertices: Set[Vertex],\n",
    "    edges: Set[Edge],\n",
    "    positiveConstraints: Set[Edge],\n",
    "    negativeConstraints: Set[Edge],\n",
    "    weights: Map[Edge, Double]\n",
    ") {\n",
    "    def cohD(assignment: Map[Vertex, Boolean]): Double = {\n",
    "        def eval(vertex: Vertex): Double = {\n",
    "            if(assignment.get(vertex).getOrElse(false)) dataWeights.get(vertex).getOrElse(0.0)\n",
    "            else 0.0\n",
    "        }\n",
    "        vertices.toList.map(eval).sum\n",
    "    }\n",
    "    \n",
    "    override def coh(assignment: Map[Vertex, Boolean]): Double = {\n",
    "        cohPlus(assignment) + cohMinus(assignment) + cohD(assignment)\n",
    "    }\n",
    "}\n",
    "\n",
    "case object DiscriminatingNetwork {\n",
    "    def apply(\n",
    "        vertices: Set[Vertex],\n",
    "        edges: Set[Edge],\n",
    "        positiveConstraints: Set[Edge],\n",
    "        negativeConstraints: Set[Edge],\n",
    "        weights: Map[Edge, Double],\n",
    "        dataWeights: Map[Vertex, Double]\n",
    "    ): DiscriminatingNetwork = {\n",
    "        new DiscriminatingNetwork(\n",
    "            vertices,\n",
    "            edges: Set[Edge],\n",
    "            positiveConstraints,\n",
    "            negativeConstraints,\n",
    "            weights,\n",
    "            dataWeights\n",
    "        )\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating discriminating coherence value\n",
    "\n",
    "Another small example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mdNet\u001b[39m: \u001b[32mDiscriminatingNetwork\u001b[39m = \u001b[33mNetwork\u001b[39m(\n",
       "  vertices = \u001b[33mSet\u001b[39m(\u001b[32m\"a\"\u001b[39m, \u001b[32m\"b\"\u001b[39m),\n",
       "  edges = \u001b[33mSet\u001b[39m((\u001b[32m\"a\"\u001b[39m, \u001b[32m\"b\"\u001b[39m)),\n",
       "  positiveConstraints = \u001b[33mSet\u001b[39m((\u001b[32m\"a\"\u001b[39m, \u001b[32m\"b\"\u001b[39m)),\n",
       "  negativeConstraints = \u001b[33mSet\u001b[39m(),\n",
       "  weights = \u001b[33mMap\u001b[39m((\u001b[32m\"a\"\u001b[39m, \u001b[32m\"b\"\u001b[39m) -> \u001b[32m0.4\u001b[39m)\n",
       ")\n",
       "\u001b[36mtruthValueAssignment\u001b[39m: \u001b[32mMap\u001b[39m[\u001b[32mString\u001b[39m, \u001b[32mBoolean\u001b[39m] = \u001b[33mMap\u001b[39m(\u001b[32m\"a\"\u001b[39m -> \u001b[32mtrue\u001b[39m, \u001b[32m\"b\"\u001b[39m -> \u001b[32mfalse\u001b[39m)\n",
       "\u001b[36mres8_2\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.8\u001b[39m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dNet = DiscriminatingNetwork(\n",
    "    vertices = Set(\"a\", \"b\"),\n",
    "    edges = Set((\"a\", \"b\")),\n",
    "    positiveConstraints = Set((\"a\", \"b\")),\n",
    "    negativeConstraints = Set.empty,\n",
    "    weights = Map((\"a\",\"b\") -> 0.4),\n",
    "    dataWeights = Map((\"a\" -> 0.8))\n",
    ")\n",
    "val truthValueAssignment = Map(\"a\" -> true, \"b\" -> false)\n",
    "dNet.coh(truthValueAssignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminating Coherence\n",
    "\n",
    "The implementation of <span style=\"font-variant: small-caps;\">Discriminating Coherence</span> builds on the ```DiscriminatingNetwork``` data structure. Where otherwise we would list the input of the formalization in full, namely:\n",
    "```\n",
    "def discriminatingCoherence(\n",
    "        vertices: Set[Vertex],\n",
    "        edges: Set[Edge],\n",
    "        positiveConstraints: Set[Edge],\n",
    "        negativeConstraints: Set[Edge],\n",
    "        weights: Map[Edge, Double],\n",
    "        dWeights: Map[Vertex, Double]\n",
    "    ): Map[Vertex, Boolean] = {\n",
    "}\n",
    "```\n",
    "it is here contained in the datastructure. We also do not need to implement the coherence value function, since it is implemented in ```DiscriminatingCoherenceNetwork```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mdiscriminatingCoherence\u001b[39m"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def discriminatingCoherence(network: DiscriminatingNetwork): Map[Vertex, Boolean] = {\n",
    "    network.vertices.allMappings(Set(true, false))\n",
    "    .argMax(network.coh _)\n",
    "    .random.get\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this implementation to find the truth value assignment with maximal coherence value as follows (reusing ```dNet``` from before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mdCohOut\u001b[39m: \u001b[32mMap\u001b[39m[\u001b[32mVertex\u001b[39m, \u001b[32mBoolean\u001b[39m] = \u001b[33mMap\u001b[39m(\u001b[32m\"a\"\u001b[39m -> \u001b[32mtrue\u001b[39m, \u001b[32m\"b\"\u001b[39m -> \u001b[32mtrue\u001b[39m)\n",
       "\u001b[36mcoherenceValue\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m1.2000000000000002\u001b[39m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dCohOut = discriminatingCoherence(dNet)\n",
    "val coherenceValue = dNet.coh(dCohOut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Connectionist Discriminating Coherence Algorithm\n",
    "\n",
    "The connectinist coherence algorithm takes a ```discriminatingNetwork``` and transforms it into a connectionnist network. It changes all weights for positive constraints to ```excitatoryWeight```, it changes weights for negative constraints to ```inhibitoryWeight```. It adds a special node ```_s_``` to which all data nodes are connected with weight ```dataWeight```. Node activation initial states are ```initSpecial``` for the special node ```_s_```, ```initOther``` for all other nodes.\n",
    "\n",
    "The propagation of activations is implemented recursively in the ```step``` subfunction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mconnectionistDCoherence\u001b[39m"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def connectionistDCoherence(\n",
    "    network: DiscriminatingNetwork,\n",
    "    initSpecial: Double,\n",
    "    initOther: Double,\n",
    "    min: Double,\n",
    "    max: Double,\n",
    "    decay: Double,\n",
    "    minChange: Double,\n",
    "    maxEpochs: Int,\n",
    "    excitatoryWeight: Double,\n",
    "    dataWeight: Double,\n",
    "    inhibitoryWeight: Double\n",
    "): Map[Vertex, Boolean] = {\n",
    "    val vertices: Set[Vertex] = network.vertices\n",
    "    val edges: Set[Edge] = network.edges\n",
    "    val positiveConstraints: Set[Edge] = network.positiveConstraints\n",
    "    val negativeConstraints: Set[Edge] = network.negativeConstraints\n",
    "    val weights: Map[Edge, Double] = network.weights\n",
    "    val dataWeights: Map[Vertex, Double] = network.dataWeights\n",
    "    \n",
    "    val specialVertex: (Vertex, Double) = \"_s_\" -> initSpecial\n",
    "    \n",
    "    def initActivations: Map[Vertex, Double] = {\n",
    "        val activations = vertices.map(v => {\n",
    "            v -> initOther\n",
    "        }).toMap\n",
    "        \n",
    "        activations + specialVertex\n",
    "    }\n",
    "    \n",
    "    val weight: Map[Edge, Double] = {\n",
    "        val specialWeights = dataWeights.keySet.map(d => {\n",
    "            (\"_s_\", d) -> dataWeight\n",
    "        })\n",
    "        \n",
    "        val weights = edges.map(e => {\n",
    "            if(e in positiveConstraints) e -> excitatoryWeight\n",
    "            else e -> inhibitoryWeight\n",
    "        }).toMap\n",
    "        \n",
    "        weights ++ specialWeights\n",
    "    }\n",
    "    \n",
    "    def net(vertex: Vertex, activations: Map[Vertex, Double]): Double = {\n",
    "        val n = weight\n",
    "            .map(ew => {\n",
    "                val e = ew._1\n",
    "                val w = ew._2\n",
    "                if(e._1 == vertex) w * activations(e._2)\n",
    "                else if(e._2 == vertex) w * activations(e._1)\n",
    "                else 0.0\n",
    "            })\n",
    "            .sum\n",
    "        math.max(min, math.min(max,n))  // hard limit\n",
    "        // n / weight.filter(ew => ew._1._1 == vertex || ew._1._2 == vertex).size // normalize by # neighbours as defined in Thagard & Verbeurgt (1998)\n",
    "    }\n",
    "    \n",
    "    def step(activations: Map[Vertex, Double], epoch: Int = 0): Map[Vertex, Double] = {\n",
    "        val newActivations = vertices.map(vertex => {\n",
    "            val a_v_t = activations(vertex)\n",
    "            val n = net(vertex, activations)\n",
    "            \n",
    "            val newActivation = a_v_t * (1 - decay) + {\n",
    "                if(n > 0) n * (max - a_v_t)\n",
    "                else n * (a_v_t - min)\n",
    "            }\n",
    "            \n",
    "            vertex -> newActivation\n",
    "        }).toMap + specialVertex\n",
    "        \n",
    "        val biggestChange = vertices.toList.map(v => math.abs(activations(v) - newActivations(v))).max\n",
    "        \n",
    "        if(epoch > maxEpochs || biggestChange < minChange) newActivations\n",
    "        else step(newActivations, epoch + 1)\n",
    "    }\n",
    "    \n",
    "    def discretizeOutput(activations: Map[Vertex, Double]): Map[Vertex, Boolean] = {\n",
    "        activations.view.mapValues(_ > 0).toMap.filter(_._1 != \"_s_\")\n",
    "    }\n",
    "    \n",
    "    discretizeOutput(step(initActivations))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "We use the Netherlands belief network example to explore the different between the computational-level  and algorithmic-level theory. In principle, we can provide different weights to each individual constraint, but in this example we follow Thagard & Verbeurgt's (1998) parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** OPTIMAL NETWORK ***\n",
      "e\tNijmegen is the capital is true\n",
      "f\tParliament is in the Hague is true\n",
      "a\tAmsterdam is the largest city is true\n",
      "i\tPrime minister lives in The Hague is true\n",
      "b\tNijmegen is the oldest city is true\n",
      "g\tParliament is in Amsterdam is true\n",
      "d\tAmsterdam is the capital is true\n",
      "c\tThe Hague is the capital is true\n",
      "h\tParliament is in Nijmegen is true\n",
      "** NEURAL NETWORK ***\n",
      "e\tNijmegen is the capital is false\n",
      "f\tParliament is in the Hague is true\n",
      "a\tAmsterdam is the largest city is true\n",
      "i\tPrime minister lives in The Hague is true\n",
      "b\tNijmegen is the oldest city is false\n",
      "g\tParliament is in Amsterdam is false\n",
      "d\tAmsterdam is the capital is true\n",
      "c\tThe Hague is the capital is true\n",
      "h\tParliament is in Nijmegen is false\n",
      "Belief\tOpt\tNN\n",
      "a\ttrue\ttrue\n",
      "b\ttrue\tfalse\n",
      "c\ttrue\ttrue\n",
      "d\ttrue\ttrue\n",
      "e\ttrue\tfalse\n",
      "f\ttrue\ttrue\n",
      "g\ttrue\tfalse\n",
      "h\ttrue\tfalse\n",
      "i\ttrue\ttrue\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mvertices\u001b[39m: \u001b[32mSet\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mHashSet\u001b[39m(\u001b[32m\"e\"\u001b[39m, \u001b[32m\"f\"\u001b[39m, \u001b[32m\"a\"\u001b[39m, \u001b[32m\"i\"\u001b[39m, \u001b[32m\"b\"\u001b[39m, \u001b[32m\"g\"\u001b[39m, \u001b[32m\"d\"\u001b[39m, \u001b[32m\"c\"\u001b[39m, \u001b[32m\"h\"\u001b[39m)\n",
       "\u001b[36mpositiveConstraints\u001b[39m: \u001b[32mSet\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m)] = \u001b[33mHashSet\u001b[39m(\n",
       "  (\u001b[32m\"a\"\u001b[39m, \u001b[32m\"d\"\u001b[39m),\n",
       "  (\u001b[32m\"d\"\u001b[39m, \u001b[32m\"g\"\u001b[39m),\n",
       "  (\u001b[32m\"e\"\u001b[39m, \u001b[32m\"h\"\u001b[39m),\n",
       "  (\u001b[32m\"f\"\u001b[39m, \u001b[32m\"i\"\u001b[39m),\n",
       "  (\u001b[32m\"c\"\u001b[39m, \u001b[32m\"f\"\u001b[39m),\n",
       "  (\u001b[32m\"b\"\u001b[39m, \u001b[32m\"e\"\u001b[39m)\n",
       ")\n",
       "\u001b[36mnegativeConstraints\u001b[39m: \u001b[32mSet\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m)] = \u001b[33mHashSet\u001b[39m(\n",
       "  (\u001b[32m\"a\"\u001b[39m, \u001b[32m\"b\"\u001b[39m),\n",
       "  (\u001b[32m\"d\"\u001b[39m, \u001b[32m\"e\"\u001b[39m),\n",
       "  (\u001b[32m\"c\"\u001b[39m, \u001b[32m\"e\"\u001b[39m),\n",
       "  (\u001b[32m\"g\"\u001b[39m, \u001b[32m\"i\"\u001b[39m),\n",
       "  (\u001b[32m\"f\"\u001b[39m, \u001b[32m\"g\"\u001b[39m),\n",
       "  (\u001b[32m\"c\"\u001b[39m, \u001b[32m\"d\"\u001b[39m),\n",
       "  (\u001b[32m\"h\"\u001b[39m, \u001b[32m\"i\"\u001b[39m),\n",
       "  (\u001b[32m\"a\"\u001b[39m, \u001b[32m\"c\"\u001b[39m),\n",
       "  (\u001b[32m\"f\"\u001b[39m, \u001b[32m\"h\"\u001b[39m)\n",
       ")\n",
       "\u001b[36medges\u001b[39m: \u001b[32mSet\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m)] = \u001b[33mHashSet\u001b[39m(\n",
       "  (\u001b[32m\"a\"\u001b[39m, \u001b[32m\"d\"\u001b[39m),\n",
       "  (\u001b[32m\"a\"\u001b[39m, \u001b[32m\"b\"\u001b[39m),\n",
       "  (\u001b[32m\"d\"\u001b[39m, \u001b[32m\"e\"\u001b[39m),\n",
       "  (\u001b[32m\"c\"\u001b[39m, \u001b[32m\"e\"\u001b[39m),\n",
       "  (\u001b[32m\"g\"\u001b[39m, \u001b[32m\"i\"\u001b[39m),\n",
       "  (\u001b[32m\"f\"\u001b[39m, \u001b[32m\"g\"\u001b[39m),\n",
       "  (\u001b[32m\"h\"\u001b[39m, \u001b[32m\"i\"\u001b[39m),\n",
       "  (\u001b[32m\"d\"\u001b[39m, \u001b[32m\"g\"\u001b[39m),\n",
       "  (\u001b[32m\"b\"\u001b[39m, \u001b[32m\"e\"\u001b[39m),\n",
       "  (\u001b[32m\"c\"\u001b[39m, \u001b[32m\"f\"\u001b[39m),\n",
       "  (\u001b[32m\"c\"\u001b[39m, \u001b[32m\"d\"\u001b[39m),\n",
       "  (\u001b[32m\"a\"\u001b[39m, \u001b[32m\"c\"\u001b[39m),\n",
       "  (\u001b[32m\"e\"\u001b[39m, \u001b[32m\"h\"\u001b[39m),\n",
       "  (\u001b[32m\"f\"\u001b[39m, \u001b[32m\"i\"\u001b[39m),\n",
       "  (\u001b[32m\"f\"\u001b[39m, \u001b[32m\"h\"\u001b[39m)\n",
       ")\n",
       "\u001b[36mweights\u001b[39m: \u001b[32mMap\u001b[39m[\u001b[32mEdge\u001b[39m, \u001b[32mDouble\u001b[39m] = \u001b[33mHashMap\u001b[39m(\n",
       "  (\u001b[32m\"a\"\u001b[39m, \u001b[32m\"d\"\u001b[39m) -> \u001b[32m0.4\u001b[39m,\n",
       "  (\u001b[32m\"a\"\u001b[39m, \u001b[32m\"b\"\u001b[39m) -> \u001b[32m-0.6\u001b[39m,\n",
       "  (\u001b[32m\"d\"\u001b[39m, \u001b[32m\"e\"\u001b[39m) -> \u001b[32m-0.6\u001b[39m,\n",
       "  (\u001b[32m\"c\"\u001b[39m, \u001b[32m\"e\"\u001b[39m) -> \u001b[32m-0.6\u001b[39m,\n",
       "  (\u001b[32m\"g\"\u001b[39m, \u001b[32m\"i\"\u001b[39m) -> \u001b[32m-0.6\u001b[39m,\n",
       "  (\u001b[32m\"f\"\u001b[39m, \u001b[32m\"g\"\u001b[39m) -> \u001b[32m-0.6\u001b[39m,\n",
       "  (\u001b[32m\"h\"\u001b[39m, \u001b[32m\"i\"\u001b[39m) -> \u001b[32m-0.6\u001b[39m,\n",
       "  (\u001b[32m\"d\"\u001b[39m, \u001b[32m\"g\"\u001b[39m) -> \u001b[32m0.4\u001b[39m,\n",
       "  (\u001b[32m\"b\"\u001b[39m, \u001b[32m\"e\"\u001b[39m) -> \u001b[32m0.4\u001b[39m,\n",
       "  (\u001b[32m\"c\"\u001b[39m, \u001b[32m\"f\"\u001b[39m) -> \u001b[32m0.4\u001b[39m,\n",
       "  (\u001b[32m\"c\"\u001b[39m, \u001b[32m\"d\"\u001b[39m) -> \u001b[32m-0.6\u001b[39m,\n",
       "  (\u001b[32m\"a\"\u001b[39m, \u001b[32m\"c\"\u001b[39m) -> \u001b[32m-0.6\u001b[39m,\n",
       "  (\u001b[32m\"e\"\u001b[39m, \u001b[32m\"h\"\u001b[39m) -> \u001b[32m0.4\u001b[39m,\n",
       "  (\u001b[32m\"f\"\u001b[39m, \u001b[32m\"i\"\u001b[39m) -> \u001b[32m0.4\u001b[39m,\n",
       "  (\u001b[32m\"f\"\u001b[39m, \u001b[32m\"h\"\u001b[39m) -> \u001b[32m-0.6\u001b[39m\n",
       ")\n",
       "\u001b[36mdataWeights\u001b[39m: \u001b[32mMap\u001b[39m[\u001b[32mVertex\u001b[39m, \u001b[32mDouble\u001b[39m] = \u001b[33mHashMap\u001b[39m(\n",
       "  \u001b[32m\"a\"\u001b[39m -> \u001b[32m0.5\u001b[39m,\n",
       "  \u001b[32m\"i\"\u001b[39m -> \u001b[32m0.5\u001b[39m,\n",
       "  \u001b[32m\"g\"\u001b[39m -> \u001b[32m0.5\u001b[39m,\n",
       "  \u001b[32m\"c\"\u001b[39m -> \u001b[32m0.5\u001b[39m,\n",
       "  \u001b[32m\"d\"\u001b[39m -> \u001b[32m0.5\u001b[39m\n",
       ")\n",
       "\u001b[36mdNet\u001b[39m: \u001b[32mDiscriminatingNetwork\u001b[39m = \u001b[33mNetwork\u001b[39m(\n",
       "  vertices = \u001b[33mHashSet\u001b[39m(\u001b[32m\"e\"\u001b[39m, \u001b[32m\"f\"\u001b[39m, \u001b[32m\"a\"\u001b[39m, \u001b[32m\"i\"\u001b[39m, \u001b[32m\"b\"\u001b[39m, \u001b[32m\"g\"\u001b[39m, \u001b[32m\"d\"\u001b[39m, \u001b[32m\"c\"\u001b[39m, \u001b[32m\"h\"\u001b[39m),\n",
       "  edges = \u001b[33mHashSet\u001b[39m(\n",
       "    (\u001b[32m\"a\"\u001b[39m, \u001b[32m\"d\"\u001b[39m),\n",
       "    (\u001b[32m\"a\"\u001b[39m, \u001b[32m\"b\"\u001b[39m),\n",
       "    (\u001b[32m\"d\"\u001b[39m, \u001b[32m\"e\"\u001b[39m),\n",
       "    (\u001b[32m\"c\"\u001b[39m, \u001b[32m\"e\"\u001b[39m),\n",
       "    (\u001b[32m\"g\"\u001b[39m, \u001b[32m\"i\"\u001b[39m),\n",
       "    (\u001b[32m\"f\"\u001b[39m, \u001b[32m\"g\"\u001b[39m),\n",
       "    (\u001b[32m\"h\"\u001b[39m, \u001b[32m\"i\"\u001b[39m),\n",
       "    (\u001b[32m\"d\"\u001b[39m, \u001b[32m\"g\"\u001b[39m),\n",
       "    (\u001b[32m\"b\"\u001b[39m, \u001b[32m\"e\"\u001b[39m),\n",
       "    (\u001b[32m\"c\"\u001b[39m, \u001b[32m\"f\"\u001b[39m),\n",
       "    (\u001b[32m\"c\"\u001b[39m, \u001b[32m\"d\"\u001b[39m),\n",
       "    (\u001b[32m\"a\"\u001b[39m, \u001b[32m\"c\"\u001b[39m),\n",
       "    (\u001b[32m\"e\"\u001b[39m, \u001b[32m\"h\"\u001b[39m),\n",
       "    (\u001b[32m\"f\"\u001b[39m, \u001b[32m\"i\"\u001b[39m),\n",
       "    (\u001b[32m\"f\"\u001b[39m, \u001b[32m\"h\"\u001b[39m)\n",
       "  ),\n",
       "  positiveConstraints = \u001b[33mHashSet\u001b[39m(\n",
       "    (\u001b[32m\"a\"\u001b[39m, \u001b[32m\"d\"\u001b[39m),\n",
       "    (\u001b[32m\"d\"\u001b[39m, \u001b[32m\"g\"\u001b[39m),\n",
       "    (\u001b[32m\"e\"\u001b[39m, \u001b[32m\"h\"\u001b[39m),\n",
       "    (\u001b[32m\"f\"\u001b[39m, \u001b[32m\"i\"\u001b[39m),\n",
       "    (\u001b[32m\"c\"\u001b[39m, \u001b[32m\"f\"\u001b[39m),\n",
       "    (\u001b[32m\"b\"\u001b[39m, \u001b[32m\"e\"\u001b[39m)\n",
       "  ),\n",
       "  negativeConstraints = \u001b[33mHashSet\u001b[39m(\n",
       "    (\u001b[32m\"a\"\u001b[39m, \u001b[32m\"b\"\u001b[39m),\n",
       "    (\u001b[32m\"d\"\u001b[39m, \u001b[32m\"e\"\u001b[39m),\n",
       "    (\u001b[32m\"c\"\u001b[39m, \u001b[32m\"e\"\u001b[39m),\n",
       "    (\u001b[32m\"g\"\u001b[39m, \u001b[32m\"i\"\u001b[39m),\n",
       "    (\u001b[32m\"f\"\u001b[39m, \u001b[32m\"g\"\u001b[39m),\n",
       "    (\u001b[32m\"c\"\u001b[39m, \u001b[32m\"d\"\u001b[39m),\n",
       "    (\u001b[32m\"h\"\u001b[39m, \u001b[32m\"i\"\u001b[39m),\n",
       "    (\u001b[32m\"a\"\u001b[39m, \u001b[32m\"c\"\u001b[39m),\n",
       "    (\u001b[32m\"f\"\u001b[39m, \u001b[32m\"h\"\u001b[39m)\n",
       "  ),\n",
       "  weights = \u001b[33mHashMap\u001b[39m(\n",
       "...\n",
       "\u001b[36mdiscOutputOpt\u001b[39m: \u001b[32mMap\u001b[39m[\u001b[32mVertex\u001b[39m, \u001b[32mBoolean\u001b[39m] = \u001b[33mHashMap\u001b[39m(\n",
       "  \u001b[32m\"e\"\u001b[39m -> \u001b[32mtrue\u001b[39m,\n",
       "  \u001b[32m\"f\"\u001b[39m -> \u001b[32mtrue\u001b[39m,\n",
       "  \u001b[32m\"a\"\u001b[39m -> \u001b[32mtrue\u001b[39m,\n",
       "  \u001b[32m\"i\"\u001b[39m -> \u001b[32mtrue\u001b[39m,\n",
       "  \u001b[32m\"b\"\u001b[39m -> \u001b[32mtrue\u001b[39m,\n",
       "  \u001b[32m\"g\"\u001b[39m -> \u001b[32mtrue\u001b[39m,\n",
       "  \u001b[32m\"d\"\u001b[39m -> \u001b[32mtrue\u001b[39m,\n",
       "  \u001b[32m\"c\"\u001b[39m -> \u001b[32mtrue\u001b[39m,\n",
       "  \u001b[32m\"h\"\u001b[39m -> \u001b[32mtrue\u001b[39m\n",
       ")\n",
       "\u001b[36mneuralOutputOpt\u001b[39m: \u001b[32mMap\u001b[39m[\u001b[32mVertex\u001b[39m, \u001b[32mBoolean\u001b[39m] = \u001b[33mHashMap\u001b[39m(\n",
       "  \u001b[32m\"e\"\u001b[39m -> \u001b[32mfalse\u001b[39m,\n",
       "  \u001b[32m\"f\"\u001b[39m -> \u001b[32mtrue\u001b[39m,\n",
       "  \u001b[32m\"a\"\u001b[39m -> \u001b[32mtrue\u001b[39m,\n",
       "  \u001b[32m\"i\"\u001b[39m -> \u001b[32mtrue\u001b[39m,\n",
       "  \u001b[32m\"b\"\u001b[39m -> \u001b[32mfalse\u001b[39m,\n",
       "  \u001b[32m\"g\"\u001b[39m -> \u001b[32mfalse\u001b[39m,\n",
       "  \u001b[32m\"d\"\u001b[39m -> \u001b[32mtrue\u001b[39m,\n",
       "  \u001b[32m\"c\"\u001b[39m -> \u001b[32mtrue\u001b[39m,\n",
       "  \u001b[32m\"h\"\u001b[39m -> \u001b[32mfalse\u001b[39m\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val vertices = Set(\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\")\n",
    "val positiveConstraints = Set(\n",
    "    (\"a\",\"d\"),\n",
    "    (\"b\",\"e\"),\n",
    "    (\"c\",\"f\"),\n",
    "    (\"d\",\"g\"),\n",
    "    (\"e\",\"h\"),\n",
    "    (\"f\",\"i\")\n",
    ")\n",
    "val negativeConstraints = Set(\n",
    "    (\"a\",\"b\"),\n",
    "    (\"a\",\"c\"),\n",
    "    (\"c\",\"d\"),\n",
    "    (\"c\",\"e\"),\n",
    "    (\"d\",\"e\"),\n",
    "    (\"f\",\"g\"),\n",
    "    (\"f\",\"h\"),\n",
    "    (\"g\",\"i\"),\n",
    "    (\"h\",\"i\")\n",
    ")\n",
    "val edges = positiveConstraints \\/ negativeConstraints\n",
    "val weights: Map[Edge, Double] = Map(\n",
    "    // positive constraints\n",
    "    (\"a\",\"d\") -> 0.4,\n",
    "    (\"b\",\"e\") -> 0.4,\n",
    "    (\"c\",\"f\") -> 0.4,\n",
    "    (\"d\",\"g\") -> 0.4,\n",
    "    (\"e\",\"h\") -> 0.4,\n",
    "    (\"f\",\"i\") -> 0.4,\n",
    "    // negative constraints\n",
    "    (\"a\",\"b\") -> -0.6,\n",
    "    (\"a\",\"c\") -> -0.6,\n",
    "    (\"c\",\"d\") -> -0.6,\n",
    "    (\"c\",\"e\") -> -0.6,\n",
    "    (\"d\",\"e\") -> -0.6,\n",
    "    (\"f\",\"g\") -> -0.6,\n",
    "    (\"f\",\"h\") -> -0.6,\n",
    "    (\"g\",\"i\") -> -0.6,\n",
    "    (\"h\",\"i\") -> -0.6\n",
    ")\n",
    "\n",
    "val dataWeights: Map[Vertex, Double] = Map(\n",
    "    \"a\" -> 0.5,\n",
    "    \"c\" -> 0.5,\n",
    "    \"d\" -> 0.5,\n",
    "    \"g\" -> 0.5,\n",
    "    \"i\" -> 0.5\n",
    ")\n",
    "\n",
    "val dNet = DiscriminatingNetwork(\n",
    "    vertices,\n",
    "    edges,\n",
    "    positiveConstraints,\n",
    "    negativeConstraints,\n",
    "    weights,\n",
    "    dataWeights\n",
    ")\n",
    "\n",
    "val discOutputOpt = discriminatingCoherence(dNet)\n",
    "println(\"** OPTIMAL NETWORK ***\")\n",
    "dNet.vertices.foreach(bel => println(s\"$bel\\t${dict(bel)} is ${discOutputOpt(bel)}\"))\n",
    "\n",
    "val neuralOutputOpt = connectionistDCoherence(\n",
    "    dNet,\n",
    "    initSpecial = 1.0,\n",
    "    initOther = 0.1,\n",
    "    min = -1,\n",
    "    max = 1,\n",
    "    decay = 0.05,\n",
    "    minChange = 0.01,\n",
    "    maxEpochs = 200,\n",
    "    excitatoryWeight = 0.4,\n",
    "    dataWeight = 0.5,\n",
    "    inhibitoryWeight = -0.6\n",
    "    \n",
    ")\n",
    "println(\"** NEURAL NETWORK ***\")\n",
    "beliefs.foreach(bel => println(s\"$bel\\t${dict(bel)} is ${neuralOutputOpt(bel)}\"))\n",
    "\n",
    "\n",
    "println(\"Belief\\tOpt\\tNN\")\n",
    "beliefs.toSeq.sorted.foreach(bel => println(s\"$bel\\t${discOutputOpt(bel)}\\t${neuralOutputOpt(bel)}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Random Networks\n",
    "\n",
    "The object ```RandomNetwork``` provides supporting code for generating random belief networks. It provides limited ways of manipulating properties of the generated networks.\n",
    "\n",
    "\n",
    "* ```size``` is an integer ```size```$> 0$ and specifies the exact number of vertices that the generated network contains.\n",
    "* ```density``` is a double $0\\leq$ ```density``` $\\leq 1$ and specifies the percentage of edges. For example, ```density = 0.4``` means that a random generated network of size $12$ will have $\\lfloor 12^2\\cdot 0.4\\rfloor=57$ edges.\n",
    "* ```ratioPosNeg``` is a double $0\\leq$ ```ratioPosNeg``` $\\leq 1$ and specifies the ratio between positive and negative constraints for the edges. For example, ```ratioPosNeg = 0.2``` means that a random generated network with $8$ edges will have $\\lfloor 8\\cdot 0.2\\rfloor=1$ positive constraint and $8-1=7$ negative constraints.\n",
    "* ```ratioPosNeg``` is a double $0\\leq$ ```ratioPosNeg``` $\\leq 1$ and specifies the percentage of nodes that are data nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mobject\u001b[39m \u001b[36mRandomNetwork\u001b[39m"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case object RandomNetwork {\n",
    "    \n",
    "    def nextDNetwork(\n",
    "        size: Int,\n",
    "        density: Double,\n",
    "        ratioPosNeg: Double,\n",
    "        dataRatio: Double\n",
    "    ): DiscriminatingNetwork = {\n",
    "        val elements = (0 until size)\n",
    "            .map(i => s\"V$i\")\n",
    "            .toSet\n",
    "        val nrEdges = (density * size).intValue\n",
    "        val edgeList = Random.shuffle(elements.uniquePairs.toList).take(nrEdges)\n",
    "        val nrPosConstraints = (ratioPosNeg * edgeList.size).intValue\n",
    "        val positiveConstraints = edgeList.take(nrPosConstraints).toSet\n",
    "        val negativeConstraints = edgeList.drop(nrPosConstraints).toSet\n",
    "        val weights = (positiveConstraints \\/ negativeConstraints).map(_ -> Random.nextDouble()).toMap\n",
    "        val dataWeights = Random.shuffle(elements.toList).take((size * dataRatio).intValue).map(_ -> Random.nextDouble()).toMap\n",
    "        \n",
    "        DiscriminatingNetwork(\n",
    "            vertices = elements,\n",
    "            edges = positiveConstraints \\/ negativeConstraints, \n",
    "            positiveConstraints,\n",
    "            negativeConstraints,\n",
    "            weights,\n",
    "            dataWeights\n",
    "        )\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres25\u001b[39m: \u001b[32mDiscriminatingNetwork\u001b[39m = \u001b[33mNetwork\u001b[39m(\n",
       "  vertices = \u001b[33mHashSet\u001b[39m(\u001b[32m\"V4\"\u001b[39m, \u001b[32m\"V3\"\u001b[39m, \u001b[32m\"V2\"\u001b[39m, \u001b[32m\"V7\"\u001b[39m, \u001b[32m\"V5\"\u001b[39m, \u001b[32m\"V0\"\u001b[39m, \u001b[32m\"V1\"\u001b[39m, \u001b[32m\"V6\"\u001b[39m),\n",
       "  edges = \u001b[33mHashSet\u001b[39m(\n",
       "    (\u001b[32m\"V5\"\u001b[39m, \u001b[32m\"V7\"\u001b[39m),\n",
       "    (\u001b[32m\"V7\"\u001b[39m, \u001b[32m\"V0\"\u001b[39m),\n",
       "    (\u001b[32m\"V1\"\u001b[39m, \u001b[32m\"V6\"\u001b[39m),\n",
       "    (\u001b[32m\"V7\"\u001b[39m, \u001b[32m\"V3\"\u001b[39m),\n",
       "    (\u001b[32m\"V6\"\u001b[39m, \u001b[32m\"V1\"\u001b[39m)\n",
       "  ),\n",
       "  positiveConstraints = \u001b[33mSet\u001b[39m((\u001b[32m\"V5\"\u001b[39m, \u001b[32m\"V7\"\u001b[39m), (\u001b[32m\"V1\"\u001b[39m, \u001b[32m\"V6\"\u001b[39m)),\n",
       "  negativeConstraints = \u001b[33mSet\u001b[39m((\u001b[32m\"V7\"\u001b[39m, \u001b[32m\"V3\"\u001b[39m), (\u001b[32m\"V7\"\u001b[39m, \u001b[32m\"V0\"\u001b[39m), (\u001b[32m\"V6\"\u001b[39m, \u001b[32m\"V1\"\u001b[39m)),\n",
       "  weights = \u001b[33mHashMap\u001b[39m(\n",
       "    (\u001b[32m\"V5\"\u001b[39m, \u001b[32m\"V7\"\u001b[39m) -> \u001b[32m0.08237625218726241\u001b[39m,\n",
       "    (\u001b[32m\"V7\"\u001b[39m, \u001b[32m\"V0\"\u001b[39m) -> \u001b[32m0.1581706869307632\u001b[39m,\n",
       "    (\u001b[32m\"V1\"\u001b[39m, \u001b[32m\"V6\"\u001b[39m) -> \u001b[32m0.5910136970484955\u001b[39m,\n",
       "    (\u001b[32m\"V7\"\u001b[39m, \u001b[32m\"V3\"\u001b[39m) -> \u001b[32m0.2254619153755879\u001b[39m,\n",
       "    (\u001b[32m\"V6\"\u001b[39m, \u001b[32m\"V1\"\u001b[39m) -> \u001b[32m0.5190078907361295\u001b[39m\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomNetwork.nextDNetwork(\n",
    "    size = 8,\n",
    "    density = 0.7,\n",
    "    ratioPosNeg = 0.5,\n",
    "    dataRatio = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating many DCoherence instances\n",
    "\n",
    "The following code simulates as many DCoherence instances with  <span style=\"font-variant: small-caps;\">Discriminating Coherence</span> and ```connectionistDiscriminatingCoherence```. It computes coherence values for each returned output, relative to the input belief network and it computes the structural difference between the two algortihms' outputs (i.e., how many beliefs are assigned a different truth value).\n",
    "\n",
    "The second code block below writes the results to a (large) CSV file for analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36msize\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m12\u001b[39m\n",
       "\u001b[36mdensity\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.8\u001b[39m\n",
       "\u001b[36mratioPosNeg\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.8\u001b[39m\n",
       "\u001b[36mdataRatio\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.4\u001b[39m\n",
       "\u001b[36mnrInstances\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m1000\u001b[39m\n",
       "\u001b[36minitSpecial\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m1.0\u001b[39m\n",
       "\u001b[36minitOther\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.1\u001b[39m\n",
       "\u001b[36mmin\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m-1\u001b[39m\n",
       "\u001b[36mmax\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m1\u001b[39m\n",
       "\u001b[36mdecay\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.05\u001b[39m\n",
       "\u001b[36mminChange\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.01\u001b[39m\n",
       "\u001b[36mmaxEpochs\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m10\u001b[39m\n",
       "\u001b[36mexcitatoryWeight\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.4\u001b[39m\n",
       "\u001b[36mdataWeight\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m-0.6\u001b[39m\n",
       "\u001b[36minhibitoryWeight\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m-0.6\u001b[39m\n",
       "\u001b[36mdBeliefNetworks\u001b[39m: \u001b[32mIndexedSeq\u001b[39m[\u001b[32mDiscriminatingNetwork\u001b[39m] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mNetwork\u001b[39m(\n",
       "    vertices = \u001b[33mHashSet\u001b[39m(\n",
       "      \u001b[32m\"V9\"\u001b[39m,\n",
       "      \u001b[32m\"V10\"\u001b[39m,\n",
       "      \u001b[32m\"V3\"\u001b[39m,\n",
       "      \u001b[32m\"V2\"\u001b[39m,\n",
       "      \u001b[32m\"V7\"\u001b[39m,\n",
       "      \u001b[32m\"V8\"\u001b[39m,\n",
       "      \u001b[32m\"V5\"\u001b[39m,\n",
       "      \u001b[32m\"V0\"\u001b[39m,\n",
       "      \u001b[32m\"V11\"\u001b[39m,\n",
       "      \u001b[32m\"V4\"\u001b[39m,\n",
       "      \u001b[32m\"V1\"\u001b[39m,\n",
       "      \u001b[32m\"V6\"\u001b[39m\n",
       "    ),\n",
       "    edges = \u001b[33mHashSet\u001b[39m(\n",
       "      (\u001b[32m\"V8\"\u001b[39m, \u001b[32m\"V3\"\u001b[39m),\n",
       "      (\u001b[32m\"V4\"\u001b[39m, \u001b[32m\"V7\"\u001b[39m),\n",
       "      (\u001b[32m\"V4\"\u001b[39m, \u001b[32m\"V11\"\u001b[39m),\n",
       "      (\u001b[32m\"V1\"\u001b[39m, \u001b[32m\"V6\"\u001b[39m),\n",
       "      (\u001b[32m\"V3\"\u001b[39m, \u001b[32m\"V1\"\u001b[39m),\n",
       "      (\u001b[32m\"V3\"\u001b[39m, \u001b[32m\"V5\"\u001b[39m),\n",
       "      (\u001b[32m\"V0\"\u001b[39m, \u001b[32m\"V9\"\u001b[39m),\n",
       "      (\u001b[32m\"V9\"\u001b[39m, \u001b[32m\"V2\"\u001b[39m),\n",
       "      (\u001b[32m\"V10\"\u001b[39m, \u001b[32m\"V8\"\u001b[39m)\n",
       "    ),\n",
       "    positiveConstraints = \u001b[33mHashSet\u001b[39m(\n",
       "      (\u001b[32m\"V8\"\u001b[39m, \u001b[32m\"V3\"\u001b[39m),\n",
       "      (\u001b[32m\"V4\"\u001b[39m, \u001b[32m\"V7\"\u001b[39m),\n",
       "      (\u001b[32m\"V4\"\u001b[39m, \u001b[32m\"V11\"\u001b[39m),\n",
       "      (\u001b[32m\"V3\"\u001b[39m, \u001b[32m\"V1\"\u001b[39m),\n",
       "      (\u001b[32m\"V3\"\u001b[39m, \u001b[32m\"V5\"\u001b[39m),\n",
       "      (\u001b[32m\"V9\"\u001b[39m, \u001b[32m\"V2\"\u001b[39m),\n",
       "      (\u001b[32m\"V10\"\u001b[39m, \u001b[32m\"V8\"\u001b[39m)\n",
       "    ),\n",
       "    negativeConstraints = \u001b[33mSet\u001b[39m((\u001b[32m\"V1\"\u001b[39m, \u001b[32m\"V6\"\u001b[39m), (\u001b[32m\"V0\"\u001b[39m, \u001b[32m\"V9\"\u001b[39m)),\n",
       "    weights = \u001b[33mHashMap\u001b[39m(\n",
       "      (\u001b[32m\"V8\"\u001b[39m, \u001b[32m\"V3\"\u001b[39m) -> \u001b[32m0.7568304415791145\u001b[39m,\n",
       "...\n",
       "\u001b[36mresults\u001b[39m: \u001b[32mList\u001b[39m[(\u001b[32mDiscriminatingNetwork\u001b[39m, \u001b[32mMap\u001b[39m[\u001b[32mVertex\u001b[39m, \u001b[32mBoolean\u001b[39m], \u001b[32mDouble\u001b[39m, \u001b[32mMap\u001b[39m[\u001b[32mVertex\u001b[39m, \u001b[32mBoolean\u001b[39m], \u001b[32mDouble\u001b[39m)] = \u001b[33mList\u001b[39m(\n",
       "  (\n",
       "    \u001b[33mNetwork\u001b[39m(\n",
       "      vertices = \u001b[33mHashSet\u001b[39m(\n",
       "        \u001b[32m\"V9\"\u001b[39m,\n",
       "        \u001b[32m\"V10\"\u001b[39m,\n",
       "        \u001b[32m\"V3\"\u001b[39m,\n",
       "        \u001b[32m\"V2\"\u001b[39m,\n",
       "        \u001b[32m\"V7\"\u001b[39m,\n",
       "        \u001b[32m\"V8\"\u001b[39m,\n",
       "        \u001b[32m\"V5\"\u001b[39m,\n",
       "        \u001b[32m\"V0\"\u001b[39m,\n",
       "        \u001b[32m\"V11\"\u001b[39m,\n",
       "        \u001b[32m\"V4\"\u001b[39m,\n",
       "        \u001b[32m\"V1\"\u001b[39m,\n",
       "        \u001b[32m\"V6\"\u001b[39m\n",
       "      ),\n",
       "      edges = \u001b[33mHashSet\u001b[39m(\n",
       "        (\u001b[32m\"V8\"\u001b[39m, \u001b[32m\"V3\"\u001b[39m),\n",
       "        (\u001b[32m\"V4\"\u001b[39m, \u001b[32m\"V7\"\u001b[39m),\n",
       "        (\u001b[32m\"V4\"\u001b[39m, \u001b[32m\"V11\"\u001b[39m),\n",
       "        (\u001b[32m\"V1\"\u001b[39m, \u001b[32m\"V6\"\u001b[39m),\n",
       "        (\u001b[32m\"V3\"\u001b[39m, \u001b[32m\"V1\"\u001b[39m),\n",
       "        (\u001b[32m\"V3\"\u001b[39m, \u001b[32m\"V5\"\u001b[39m),\n",
       "        (\u001b[32m\"V0\"\u001b[39m, \u001b[32m\"V9\"\u001b[39m),\n",
       "        (\u001b[32m\"V9\"\u001b[39m, \u001b[32m\"V2\"\u001b[39m),\n",
       "        (\u001b[32m\"V10\"\u001b[39m, \u001b[32m\"V8\"\u001b[39m)\n",
       "      ),\n",
       "      positiveConstraints = \u001b[33mHashSet\u001b[39m(\n",
       "        (\u001b[32m\"V8\"\u001b[39m, \u001b[32m\"V3\"\u001b[39m),\n",
       "        (\u001b[32m\"V4\"\u001b[39m, \u001b[32m\"V7\"\u001b[39m),\n",
       "        (\u001b[32m\"V4\"\u001b[39m, \u001b[32m\"V11\"\u001b[39m),\n",
       "        (\u001b[32m\"V3\"\u001b[39m, \u001b[32m\"V1\"\u001b[39m),\n",
       "        (\u001b[32m\"V3\"\u001b[39m, \u001b[32m\"V5\"\u001b[39m),\n",
       "        (\u001b[32m\"V9\"\u001b[39m, \u001b[32m\"V2\"\u001b[39m),\n",
       "        (\u001b[32m\"V10\"\u001b[39m, \u001b[32m\"V8\"\u001b[39m)\n",
       "      ),\n",
       "      negativeConstraints = \u001b[33mSet\u001b[39m((\u001b[32m\"V1\"\u001b[39m, \u001b[32m\"V6\"\u001b[39m), (\u001b[32m\"V0\"\u001b[39m, \u001b[32m\"V9\"\u001b[39m)),\n",
       "..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Parameter settings\n",
    "val size = 12\n",
    "val density = .8\n",
    "val ratioPosNeg = .8\n",
    "val dataRatio = .4\n",
    "val nrInstances = 1000\n",
    "\n",
    "// Connectionist parameters\n",
    "val initSpecial = 1.0\n",
    "val initOther = 0.1\n",
    "val min = -1\n",
    "val max = 1\n",
    "val decay = 0.05\n",
    "val minChange = 0.01\n",
    "val maxEpochs = 10\n",
    "val excitatoryWeight = 0.4\n",
    "val dataWeight = -0.6\n",
    "val inhibitoryWeight = -0.6\n",
    "\n",
    "// Generate random belief networks\n",
    "val dBeliefNetworks = for(_ <- 0 until nrInstances) yield\n",
    "    RandomNetwork.nextDNetwork(size, density, ratioPosNeg, dataRatio)\n",
    "\n",
    "// Compute all outputs for discriminating and connectionist coherence.\n",
    "// Computations are parallelized to use multiple CPU cores, remove .par to execute in single core.\n",
    "val results = dBeliefNetworks.par\n",
    "    .map(dNetwork => {\n",
    "        val dOut = discriminatingCoherence(dNetwork)\n",
    "        val nOut = connectionistDCoherence(\n",
    "            dNetwork,\n",
    "            initSpecial,\n",
    "            initOther,\n",
    "            min,\n",
    "            max,\n",
    "            decay,\n",
    "            minChange,\n",
    "            maxEpochs,\n",
    "            excitatoryWeight,\n",
    "            dataWeight,\n",
    "            inhibitoryWeight\n",
    "        )\n",
    "        (dNetwork, dOut, dNetwork.coh(dOut), nOut, dNetwork.coh(nOut))\n",
    "    }).toList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV file description\n",
    "\n",
    "We save two CSV files relatable through a random ID number. The first CSV file contains the simulation settings which speak for themselves. The second CSV file contains on each row a single  <span style=\"font-variant: small-caps;\">Discriminating Coherence</span> and ```connectionistDiscriminatingCoherence``` simulation. The following data are stored in columns:\n",
    "\n",
    "* ```v_1..v_n``` the weights for each discriminated vertex, where regular vertices have weight 0\n",
    "* ```e_1-1..e_n-n``` the type of constraint, either ```positive```, ```negative``` or ```NA```\n",
    "* ```w_1-1..w_n-n``` the weight of the constraint, either a double value or ```NA```\n",
    "* ```opt_v_1..opt_v_n``` the truth value assignment as computed by <span style=\"font-variant: small-caps;\">Discriminating Coherence</span>\n",
    "* ```opt_coh``` the coherence value of the optimal truth value assignment\n",
    "* ```opt_v_1..opt_v_n``` the truth value assignment as computed by ```connectionistDiscriminatingCoherence```\n",
    "* ```opt_coh``` the coherence value of the connectionist truth value assignment\n",
    "* ```structSim``` the structural similarity between the connectionist truth value assignment and closest optimal truth value assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mfileID\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m6473862089548275276L\u001b[39m\n",
       "\u001b[36mfileSettings\u001b[39m: \u001b[32mFile\u001b[39m = f6473862089548275276-settings.csv\n",
       "\u001b[36msettingsWriter\u001b[39m: \u001b[32mCSVWriter\u001b[39m = com.github.tototoshi.csv.CSVWriter@47b8f70f\n",
       "\u001b[36mfileResults\u001b[39m: \u001b[32mFile\u001b[39m = f6473862089548275276-results.csv\n",
       "\u001b[36mresultsWriter\u001b[39m: \u001b[32mCSVWriter\u001b[39m = com.github.tototoshi.csv.CSVWriter@d2dfed9"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Save the simulation results to CSV file.\n",
    "val fileID = Random.nextLong().abs\n",
    "\n",
    "val fileSettings = new File(s\"f$fileID-settings.csv\")\n",
    "\n",
    "val settingsWriter = CSVWriter.open(fileSettings)\n",
    "settingsWriter.writeRow(\n",
    "    List(\n",
    "        \"size\",\n",
    "        \"density\",\n",
    "        \"ratioPosNeg\",\n",
    "        \"dataRatio\",\n",
    "        \"nrInstances\",\n",
    "        \"initSpecial\",\n",
    "        \"initOther\",\n",
    "        \"min\",\n",
    "        \"max\",\n",
    "        \"decay\",\n",
    "        \"minChange\",\n",
    "        \"maxEpochs\",\n",
    "        \"excitatoryWeight\",\n",
    "        \"dataWeight\",\n",
    "        \"inhibitoryWeight\"\n",
    "    )\n",
    ")\n",
    "settingsWriter.writeRow(\n",
    "    List(\n",
    "        size,\n",
    "        density,\n",
    "        ratioPosNeg,\n",
    "        dataRatio,\n",
    "        nrInstances,\n",
    "        initSpecial,\n",
    "        initOther,\n",
    "        min,\n",
    "        max,\n",
    "        decay,\n",
    "        minChange,\n",
    "        maxEpochs,\n",
    "        excitatoryWeight,\n",
    "        dataWeight,\n",
    "        inhibitoryWeight\n",
    "    )\n",
    ")\n",
    "\n",
    "val fileResults = new File(s\"f$fileID-results.csv\")\n",
    "val resultsWriter = CSVWriter.open(fileResults)\n",
    "\n",
    "resultsWriter.writeRow(\n",
    "    (for(i <- 1 to size) yield s\"v_$i\") ++\n",
    "    (for(i <- 1 to size; j <- 1 to size) yield s\"e_$i-$j\") ++\n",
    "    (for(i <- 1 to size; j <- 1 to size) yield s\"w_$i-$j\") ++\n",
    "    (1 to size).map(i => s\"opt_v_$i\") ++\n",
    "    List(\"opt_coh\") ++\n",
    "    (1 to size).map(i => s\"con_v_$i\") ++\n",
    "    List(\"con_coh\", \"struct_sim\")\n",
    ")\n",
    "\n",
    "results.foreach(result => resultsWriter.writeRow({\n",
    "    val dNet = result._1\n",
    "    val optOut = result._2\n",
    "    val optCoh = result._3\n",
    "    val conOut = result._4\n",
    "    val conCoh = result._5\n",
    "    \n",
    "    val vertices = dNet.vertices.toList.sorted\n",
    "    \n",
    "    // datanodes have weights, other nodes have weight 0\n",
    "    val nodeWeights: List[String] = vertices.map(v => if(dNet.dataWeights.contains(v)) dNet.dataWeights(v).toString else \"0\")\n",
    "    // is the edge a positive or negative constraint?\n",
    "    val edgeTypes: List[String] = for(vi <- vertices; vj <- vertices) yield {\n",
    "        if(dNet.positiveConstraints.contains((vi, vj)) || dNet.positiveConstraints.contains((vj, vi))) \"positive\"\n",
    "        else if(dNet.negativeConstraints.contains((vi, vj)) || dNet.negativeConstraints.contains((vj, vi))) \"negative\"\n",
    "        else \"NA\"\n",
    "    }\n",
    "    // the weights of the edges\n",
    "    val edgeWeights: List[String] = for(vi <- vertices; vj <- vertices) yield {\n",
    "        if(dNet.weights.contains((vi, vj))) dNet.weights((vi, vj)).toString\n",
    "        else if(dNet.weights.contains((vj, vi))) dNet.weights((vj, vi)).toString\n",
    "        else \"NA\"\n",
    "    }\n",
    "    // the optimal coherence output plus coherence value\n",
    "    val optResults: List[String] = vertices.map(v => optOut(v).toString) ++ List(optCoh.toString)\n",
    "    // the connectionist coherence output plus coherence value\n",
    "    val conResults: List[String] = vertices.map(v => conOut(v).toString) ++ List(conCoh.toString)\n",
    "    // the structural similarity between the connectionist truth value assignment and closest optimal truth value assignment\n",
    "    val structSim = List({\n",
    "        val allOptimalSolutions = dNet.vertices.allMappings(Set(true, false)).argMax(dNet.coh _)\n",
    "        allOptimalSolutions.map(solution => dNet.vertices.filter(v => solution(v) != conOut(v)).size).min\n",
    "    })\n",
    "    \n",
    "    nodeWeights ++ edgeTypes ++ edgeWeights ++ optResults ++ conResults ++ structSim\n",
    "}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala (2.13.12)",
   "language": "scala",
   "name": "scala21312"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
